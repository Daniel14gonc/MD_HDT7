---
title: "MD_HDT7"
---

```{r}
set.seed(123)
datos <- read.csv("train.csv")
```

```{r echo=F, include=F, load_libraries}
library(dplyr)
library(hopkins)
library(factoextra)
library(ggrepel)
library(cluster)
library(flexclust)
library(FeatureImpCluster)
library(stringr)
library(tidyr)
library(stats)
library(graphics)
library(NbClust)
library(mclust)
library(GGally)
library(corrplot)
library(caret)
library(ggplot2)
library(kableExtra)
library(e1071)
library(rpart)
library(rpart.plot)
library(naivebayes)
library(randomForest)
library(dummy)
library(profvis)
library(mlr)
library(Metrics)
```

## 1. Dvisión de variables numéricas y obtención de data de prueba y entrenamiento

### 1.1 Transformación y división de variables

Al observar las variables se puede evidenciar que hay diferentes variables que tienen datos en diferentes escalas. Además, del análisis exploratorio previo se sabe que las variables no siguen distribuciones normales, así que se escalaron y normalizaron las variables.

```{r echo=FALSE}
head(datos, )

multi_variables <- c("SalePrice", "OverallQual", "MasVnrArea", "BsmtFinSF1", "GrLivArea", "Fireplaces", "WoodDeckSF", "OpenPorchSF", "TotalBsmtSF")

num2 <- datos[, multi_variables]
datos1 <- datos[complete.cases(num2),]
datos1 <- mutate_if(datos1, is.numeric, scale)
datos1 <- datos1[, multi_variables]


variables_m2 <- c("OverallQual", "BsmtFinSF1", "BsmtUnfSF", "X2ndFlrSF", "PoolArea", "MiscVal", "Neighborhood", "HouseStyle", "LotConfig", "SalePrice")

numeric_variables <- c("OverallQual", "BsmtFinSF1", "BsmtUnfSF", "X2ndFlrSF", "PoolArea", "MiscVal", "SalePrice")

datos <- datos[, variables_m2]
cualitativas <- datos[, !(names(datos) %in% numeric_variables)]
cualitativas <- cualitativas[, !(names(cualitativas) %in% c("Id"))]

datos <- datos %>% mutate_at(colnames(cualitativas), function(x) as.factor(x))

numericas <- datos[, numeric_variables]
datos <- datos[complete.cases(numericas), ]
numericas <- na.omit(numericas)
numericas_norm <- mutate_if(numericas, is.numeric, scale)
numericas_norm <- scale(numericas_norm)
datos <- data.frame(numericas_norm, datos[, -match(numeric_variables, names(datos))])
```


### 2. Creación de clasificación de la variable de precios

```{r}
p33 <- quantile(datos$SalePrice, 0.33)
p66 <- quantile(datos$SalePrice, 0.66)

datos <- datos %>%
    mutate(clasificacion = ifelse(datos$SalePrice < p33, "Economicas",
        ifelse(datos$SalePrice < p66, "Intermedias",
            "Caras"
        )
    ))
datos$clasificacion <- as.factor(datos$clasificacion)
```


### 3. Uso de train y test previos

```{r}
head(datos)
```

```{r}
porcentaje <- 0.7
set.seed(123)

corte <- sample(nrow(datos), nrow(datos) * porcentaje)
train <- datos[corte, ]
test <- datos[-corte, ]
```


## 4. Genere varios modelos de SVM con diferentes kernels y distintos valores en c y en d

```{r}
    modeloSVM_L1<-svm(clasificacion~., data=train, cost=2^-5, kernel="linear")
    modeloSVM_L2<-svm(clasificacion~., data=train, cost=0.5, kernel="linear")
    modeloSVM_R1<-svm(clasificacion~., data=train, gamma=2^-5, kernel="radial")
    modeloSVM_R2<-svm(clasificacion~., data=train, gamma=2^1, kernel="radial")

```

## 5. Use los modelos para predecir el valor de la variable respuesta
```{r}
    Rprof(memory.profiling = TRUE)
    predicciones_L1<-predict(modeloSVM_L1, test)
    Sys.sleep(1)
    Rprof(NULL)
    pm1 <- summaryRprof(memory = "both")

    Rprof(memory.profiling = TRUE)
    predicciones_L2<-predict(modeloSVM_L2, test)
    Sys.sleep(1)
    Rprof(NULL)
    pm2 <- summaryRprof(memory = "both")

    Rprof(memory.profiling = TRUE)
    predicciones_R1<-predict(modeloSVM_R1, test)
    Sys.sleep(1)
    Rprof(NULL)
    pm3 <- summaryRprof(memory = "both")

    Rprof(memory.profiling = TRUE)
    predicciones_R2<-predict(modeloSVM_R2, test)
    Sys.sleep(1)
    Rprof(NULL)
    pm4 <- summaryRprof(memory = "both")
```

## 6. Haga las matrices de confusión respectivas

### Modelo Lineal 1
```{r}
    confusionMatrix(test$clasificacion, predicciones_L1)
```

### Modelo Lineal 2

```{r}
    confusionMatrix(test$clasificacion, predicciones_L2)
```

### Modelo Radial 1

```{r}
    confusionMatrix(test$clasificacion, predicciones_R1)
```

### Modelo Radial 2

```{r}
    confusionMatrix(test$clasificacion, predicciones_R2)
```

## 7. Analice si los modelos estan sobreajustados

```{r warning=FALSE, message=FALSE}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "linear", cost = 2^-5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")


```
Al observar la curva de aprendizaje se puede concluir que el modelo NO sufre ni de overfitting, underfitting. Esto se dice ya que tanto la curva de test como la de training están relativamente cercas en todo el trayecto, además de que ambas llegan a converger en un mismo punto al finalizar las predicciones del modelo. Por lo mismo no hay necesidad de manejar el sobreajuste o desajuste.

```{r warning=FALSE, message=FALSE}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "linear", cost = 0.5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")

```

Al observar la curva de aprendizaje, podemos notar que la curva de training empieza a bajar mientras más datos hay. Por lo tanto este modelo tiene underfitting. Para mitigar esto se puede incrementar la C del modelo para tener un boundary más rígido, de forma que se tenga menos clasificaciones erróneas.


```{r warning=FALSE, message=FALSE}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "radial", cost = 1, gamma = 2^-5, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")
```
Al observar la curva de aprendizaje se nota que la curva de training siempre va en descenso a pesar de que exista mayor cantidad de datos desde el inicio. Por lo mismo se puede considerar que este modelo posee overfitting. Para poder manejar el sobreajuste que posee este modelo se podría bajar la C para que sea más flexible y así poder aceptar mayor cantidad de errores.

```{r warning=FALSE, message=FALSE}
    datos.task = makeClassifTask(data = train, target = "clasificacion")
    rin2 = makeResampleDesc(method = "CV", iters = 10, predict = "both")
    lrn = makeLearner("classif.svm", kernel = "radial", cost = 1, gamma = 2^1, type = "C-classification")
    lc2 = generateLearningCurveData(learners = lrn, task = datos.task,
                                    percs = seq(0.1, 1, by = 0.1),
                                    measures = list(ber, setAggregation(ber, train.mean)), resampling = rin2,
                                    show.info = FALSE)
    plotLearningCurve(lc2, facet = "learner")
```

Al observar la curva de aprendisaje, podemos notar que la curva de training esta muy mala ya que es casi un linea recta y la curva de test esta muy mala ya que esta muy alejada de la curva de training. Por lo tanto este modelo tiene overfitting. Ademas de que el test tiene un margen muy amplio, por lo tanto se puede decir que el modelo no es bueno. Para mitigar esto se puede disminuir la C del modelo para tener un boundary mas flexible, de forma que se tenga menos clasificaciones erróneas.

### 8. Comparación de resultados.

#### Efectividad y equivocaviones de resultados

##### Para los modelos lineales
Para el modelo Linel 1 tenemos un accuracy de 0.89. Esto nos indica que el modelo es basatnte bueno para hacer predicciones sobre casas caras, asi mismo se puede observaciones que el modelo no tiene tantas equivocaciones con un Sensitivity de 0.97 y un Specificity 0.96.

Para el modelo Linel 2 tenemos un accuracy de 0.95. Esto nos indica que el modelo es basatnte bueno para hacer predicciones sobre casas caras mejor que el modelo pasado, asi mismo se puede observaciones que el modelo no tiene tantas equivocaciones con un Sensitivity de 0.98 y un Specificity 0.98.

##### Para los modelos Radiales

El modelo 1 tiene un Accuracy de 0.90. Esto nos idndica que es un buen modelo, ademas de no estar overtifiado, esto lo podemos respaldar con la matris de confucion ya que podemos observar que los truePositive son bien identificados y con los que mayor se llego a equivocar fueron con los Flasosnegativos de Economicas. 

En el modelo 2 se obtuvo un Accuracy de 0.75 lo cual nos indica que el modelo no es muy bueno para hacer predicciones, ademas de estar sobreajustado, esto lo podemos respaldar con la matris de confucion ya que podemos observar que los truePositive son mal identificados y con los que mayor se llego a equivocar fueron con los Flasosnegativos de Caras.

#### Tiempo de procesamiento

##### Tiempo de modelos
El modelo lineal 1 tuvo un tiempo de procesamiento de `r pm1$sampling.time`

El modelo lineal 2 tuvo un tiempo de procesamiento de `r pm2$sampling.time`

El modelo radial 1 tuvo un tiempo de procesamiento de `r pm3$sampling.time`

El modelo radial 2 tuvo un tiempo de procesamiento de `r pm4$sampling.time`

#### Conclusion
El mejor modelo es el lineal 1, porque es el unico que no posee ni sobre ni desajuste y posee un accuracy bastante elevado.

### 9. Comparación con modelos previos de clasificación.

```{r}
train_1 <- select(train, -SalePrice)
```

#### 9.1 Árbol de decisión

```{r}
modelo_arbol <- rpart(clasificacion ~ ., data = train_1, method = "class", maxdepth = 4)
rpart.plot(modelo_arbol)
pm4 <- summaryRprof(memory = "both")
y_pred <- predict(modelo_arbol, test, type = "class")
confusionMatrix(y_pred, test$clasificacion)
pm4$sampling.time
```


#### 9.2 Random Forest

```{r}
modeloRF <- randomForest(clasificacion ~ ., train_1, na.action = na.omit)
pm5 <- summaryRprof(memory = "both")
ypred <- predict(modeloRF, newdata = test)
ypred <- factor(ypred)
confusionMatrix(ypred, test$clasificacion)
```

#### 9.3 Naive Bayes

```{r}
modeloNB <- naiveBayes(clasificacion ~ ., train_1)
pm6 <- summaryRprof(memory = "both")
ypred <- predict(modeloNB, newdata = test)
ypred <- factor(ypred)
confusionMatrix(ypred, test$clasificacion)
```

Al comparar estos modelos con el mejor modelo de SVM, que fue el modelo lineal 1, es posible observar que este fue el mejor. Tuvo un accuracy de 0.89, fue el mejor modelo para clasificación de casas caras con una sensitivity de 0.97 y specificity de 0.96. Para clasificación de true positives de económicas el mejor modelo fue el de naive bayes, pero este tuvo un accuracy de 0.52, ligeramente mejor que un modelo aleatorio. Casi todos los modelos anteriores fueron muy malos para clasificación de casas intermedias, solo naive bayes tuvo un specificity de 0.98, pero en general, SVM fue superior. De los tres modelos anteriores, Random Forest tuvo el mejor accuracy con 0.76.

### 10. Modelos de Regresion 

#### 10.1 Modelo de regresión SVM

Se realizaron dummies de las variables por el encoding de la regresión de SVM. 3
```{r}

hot_encoded <- dummyVars(~Neighborhood+HouseStyle+LotConfig, data = train)
train_hot <- data.frame(predict(hot_encoded, newdata = train))
train <- cbind(train, train_hot)
train <- train[, variables_m2]

hot_encoded <- dummyVars(~Neighborhood+HouseStyle+LotConfig, data = test)
test_hot <- data.frame(predict(hot_encoded, newdata = test))
test <- cbind(test, test_hot)
test <- test[, variables_m2]
```

```{r}
modelo_svm <- svm(SalePrice ~ ., data = train, type = "eps-regression", kernel = "linear")

predicciones <- predict(modelo_svm, newdata = test)


mse(predicciones, test$SalePrice)
svmrmse <- rmse(predicciones, test$SalePrice)
svmrmse
plot(test$SalePrice, col = "blue")
points(predicciones, col = "red")
```

```{r}

r_squared <- postResample(predicciones, test$SalePrice)["Rsquared"]
r_squared

```

```{r}
predicciones_clasificacion <- ifelse(predicciones < p33, "Economicas",
                                  ifelse(predicciones < p66, "Intermedias", "Caras"))

# Crear un data frame con las predicciones y sus respectivas categorías
predicciones_df <- data.frame(Predicciones = predicciones,
                              Clasificacion = factor(predicciones_clasificacion,
                                                     levels = c("Economicas", "Intermedias", "Caras")))

head(predicciones_df)

```


#### 10.2 Regresión lineal simple

```{r}
sale_simple_model <- lm(SalePrice ~ OverallQual, data = train)
```

Luego de haber entrenado el modelo se mostraron sus características.  
```{r}
summary(sale_simple_model)
``` 
  
   
```{r}
predLM <- predict(sale_simple_model, newdata = test)
RMSE(predLM, test$SalePrice)
```

#### 10.3 Regresión lineal múltiple

```{r}
porcentaje <- 0.7
set.seed(123)
datos1 <- data.frame(datos1)
corte <- sample(nrow(datos1), nrow(datos1) * porcentaje)
train <- datos1[corte, ]
test <- datos1[-corte, ] 
```

```{r}
fitMLM_Sale <- lm(train$SalePrice ~ ., data = train)
```

```{r}
summary(fitMLM_Sale)

regresion_rmse <- RMSE(predict(fitMLM_Sale, newdata = test),test$SalePrice)
regresion_rmse
```


### 10.4 Arbol de clasificaion
```{r}

regression_tree <- rpart(formula = SalePrice ~ ., data = train)

rpart.plot(regression_tree, box.palette = "green")

ypred <- predict(regression_tree, newdata = test)

mse <- mean((ypred - test$SalePrice)^2)

# Calculate SSE
SSE <- sum((ypred - test$SalePrice)^2)

# Calculate TSS
TSS <- sum((test$SalePrice - mean(test$SalePrice))^2)

# Calculate R-squared value
r2 <- 1 - SSE / TSS

rmse <- RMSE(ypred, test$SalePrice)

# Print the results
cat("R-squared:", r2, "\n")
cat("RMSE:", rmse, "\n")


plot(test$SalePrice, col = "blue")
points(ypred, col = "red")

```

### Comparacion de los modelos

El modelo de del SVM fue el mejor de todos obteniendo un r-cuadrado de 0.80 y un RMSE de 0.44 que fue mayoe a los demas modelos con los siguientes valores: El modelo de regresión lineal múltiple obtuvo un r-cuadrado de 0.745 y un RMSE de 0.42. El modelo de regresión lineal simple obtuvo un r-cuadrado de 0.61 y un RMSE de 0.58. El modelo de árbol de clasificación obtuvo un r-cuadrado de 0.7 y un RMSE de 0.52. 

